- Class: meta
  Course: Bootstrap
  Lesson: Bootstrap Lesson
  Author: Gina Norato
  Type: Standard
  Organization: Johns Hopkins Biostatistics
  Version: 2.2.21


- Class: text
  Output: "Welcome to the Bootstrap course! Here we will learn about what boostrapping is and how it can be useful in data analysis."

- Class: video
  Output: Bootstrapping is a technique first described by Bradley Efron in a 1979 paper. Would you like to go to the article now (page will open in your default web browser)?
  VideoLink: https://projecteuclid.org/download/pdf_1/euclid.aos/1176344552
    
- Class: text
  Output: In a nutshell, bootstrapping helps us understand the sampling distribution of a particular statistic (sample mean, median, etc.), by drawing samples with replacement from the observed sample. 
  
- Class: text
  Output: When we collect data from a population to obtain a sample, we want to be able to have a measure of variability of this statistic in order to perform proper inference. Often, however, we only have the current, single sample, and getting additional unique samples may be difficult or unreasonable. We can instead take repeated sampling from our obtained sample. This mimics the acquisition of multiple samples from the population, and can help us describe the error of our statistic.
  
- Class: text
  Output: Let's look at an simple example to get some intuition.
  
  
- Class: cmd_question
  Output: Say we have a true population distribution called "pop" which is normal with mean 0 and standard deviation 2 (n=10000). Generate this sample.
  CorrectAnswer: pop <- rnorm(10000, mean = 0, sd = 2)
  AnswerTests: any_of_exprs('pop <- rnorm(10000, 0, 2)',
                              'pop = rnorm(10000, 0, 2)',
                              'pop <- rnorm(10000, mean=0, sd=2)',
                              'pop = rnorm(10000, mean=0, sd=2)',
                              'pop = rnorm(n=10000, mean=0, sd=2)',
                              'pop <- rnorm(n=10000, mean=0, sd=2)')
  Hint: Type "pop <- rnorm(10000, 0, 2)"
  
- Class: figure
  Output: Great! Let's see what that looks like. We can plot this easily with hist()
  Figure: figure1.R
  FigureType: new
  
- Class: text
  Output: Cool! Now we have our original population. Now imagine we run a study and end up with a sample of this underlying population that we can investigate. Here we will use the 'sample()' function to do this.
  
- Class: text
  Output: The 'sample()' function allows us to sample from a vector, with a certain size, and with or without replacement. We will use this function again later, but here we will just use it to generate our original sampled data. Don't forget you can access more information about this function using ?sample.
  
- Class: cmd_question
  Output: Let's try it out. Generate our sample with the command "samp <- sample(pop, size=200, replace=T)"
  CorrectAnswer: samp <- sample(pop, size=200, replace=T)
  AnswerTests: omnitest('samp <- sample(pop, size=200, replace=T)')
  Hint: Type "samp <- sample(pop, size=200, replace=T)"
  
- Class: figure
  Output: Great! Now we have a sample. Let's plot that too (using hist())
  Figure: figure2.R
  FigureType: new
  
- Class: text
  Output: Now we have a sample from our population. Let's see what the mean and sd are...
  
- Class: cmd_question
  Output: Calculate the mean and save it as samp.mean
  CorrectAnswer: samp.mean <- mean(samp)
  AnswerTests: any_of_exprs('samp.mean <- mean(samp)', 'samp.mean = mean(samp)')
  Hint: Type "samp.mean <- mean(samp)"
  
- Class: cmd_question
  Output: Now calculate the standard deviation and save it as samp.sd
  CorrectAnswer: samp.sd <- sd(samp)
  AnswerTests: any_of_exprs('samp.sd <- sd(samp)','samp.sd = sd(samp)')
  Hint: Type "samp.sd <- sd(samp)"

- Class: text
  Output: We see that our mean is pretty close to the population mean, but maybe we want to know how variable our estimate of the mean is. This is where bootstrapping comes in.

- Class: text
  Output: What we want to do is simulate taking repeated samples from the population by taking repeated samples from the obtained sample. This seems confusing, but let's try it out and get some intuition as we go.
  
- Class: cmd_question
  Output: You should remember the "sample()" function. Let's use that now to get a bootstrapped sample from our original sample. Again, we will sample this at the same size of our existing sample, and do it with replacement. Call it samp.b1
  CorrectAnswer: samp.b1 <- sample(samp, size=200, replace=T)
  AnswerTests: any_of_exprs('samp.b1 <- sample(samp, size=200, replace=T)','samp.b1 = sample(samp, size=200, replace=T)')
  Hint: Type "samp.b1 <- sample(samp, size=200, replace=T)"
  
- Class: cmd_question
  Output: Great! Now we have a bootstrapped sample, which simulates what would happen if we could take another sample from the population directly. Here we assume that our original sample is representative of the population. Let's calculate the mean and save it as samp.b1mean and see how we did.
  CorrectAnswer: samp.b1mean <- mean(samp.b1)
  AnswerTests: any_of_exprs('samp.b1mean <- mean(samp.b1)', 'samp.mean = mean(samp.b1)')
  Hint: Type "samp.b1mean <- mean(samp.b1)"
  
- Class: figure
  Output: This time, our sample mean is slightly different, which we can also visualize by plotting. Hopefully you are beginning to see the methodology here. With repeated boostrapped samples and repeated calculations of the mean, we can get a distribution of means, which can help give us a better picture of the statistic itself, in relation to the population.
  Figure: figure3.R
  FigureType: new 
  
- Class: cmd_question
  Output: You might be wondering if we have to generate all these samples by hand.. Well luckily, we don't have to! There is an R function that can help us, called "boot"! At the start of the lesson, we installed (if necessary) and loaded this library. Let's look at the help file with "?boot"
  CorrectAnswer: ?boot
  AnswerTests: omnitest('?boot')
  Hint: Type "?boot"
  
- Class: text
  Output: The boot function takes the data, the statistic to be calculated, and the number of samples to be generated. Typically, we generate as many samples as computationally feasible. Here we will just calculated 1000. I have already created a function called meanFunc to calculate the mean for each sample- the "boot" function will not just take the default mean function as an argument. You could create a similar function to calculate other statistics (ie median)
  
- Class: cmd_question
  Output: Generate the samples from "samp" and assign it to "boot"- "boot <- boot(samp,meanFunc,1000)"
  CorrectAnswer: boot <- boot(samp,meanFunc,1000)
  AnswerTests: omnitest('boot <- boot(samp,meanFunc,1000)')
  Hint: Type "boot <- boot(samp,meanFunc,1000)"
  
- Class: cmd_question
  Output: Cool! Now we have a "boot" object that we can work with. Let's plot it to see what we have
  CorrectAnswer: plot(boot)
  AnswerTests: omnitest('plot(boot)')
  Hint: Type "plot(boot)"
  
- Class: text
  Output: On the left we see a histogram of the statistic (means) of our bootstrapped samples. We can see that these values all fall very closely around 0, which we know is the true underlying mean of the population.
  
- Class: text
  Output: We can also get a confidence interval around the mean of the bootstrapped samples. There are many different methods of calculation of these intervals, all of which are available through the boot library, (and which can be read about further here <http://www.tau.ac.il/~saharon/Boot/10.1.1.133.8405.pdf>). We will use the percentile method here.
  
- Class: cmd_question
  Output: Let's get the confidence interval now- boot.ci(boot,type="perc")
  CorrectAnswer: boot.ci(boot,type="perc")
  AnswerTests: omnitest('boot.ci(boot,type="perc")')
  Hint: Type "boot.ci(boot,type="perc")"
  
- Class: text
  Output: So now we have a 95% confidence interval for how precise our estimate of the mean is for this population!
  
- Class: text
  Output: Even though there is a function, it is straightforward enough to also create the bootstrapped samples with a loop. Instead of walking you through it, I have included the code and an example in this file.
  
- Class: figure
  Output: Opening html...
  Figure: fig.R
  FigureType: new

- Class: text
  Output: Bootstrapping is also incredibly useful for creating confidence intervals for distributions that are not necessarily normally distributed. It is more robust to deviations from normality since it is only resampling from the obtained data and does not require such strict assumptions to be made. 
  

  
- Class: text
  Output: One disadvantage of using bootstrapping is that the assumption is made that the sample that is being bootstrapped from is indeed a good representation of the population. If it is too small or is a poor representation, then the bootstrapped samples will not mimic the behavior in the population.
  



  
  
  
  
  
  
  
  

